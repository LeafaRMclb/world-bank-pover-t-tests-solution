{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# data directory\n",
    "DATA_DIR = os.path.join('..', 'data')\n",
    "\n",
    "\n",
    "def load_data(country_code, data_part='train'):\n",
    "    hhold = os.path.join(DATA_DIR, '{}_hhold_{}.csv'.format(country_code, data_part))\n",
    "    indiv = os.path.join(DATA_DIR, '{}_indiv_{}.csv'.format(country_code, data_part))\n",
    "\n",
    "    hhold = pd.read_csv(hhold, index_col='id')\n",
    "    indiv = pd.read_csv(indiv, index_col=['id', 'iid'])\n",
    "\n",
    "    return hhold, indiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process to generate indiv_cat_train:\n",
    "    1. Take only categorical features\n",
    "    2. One-hot-encode the features\n",
    "    3. Summarize encoded features using:\n",
    "        - mean\n",
    "        - median\n",
    "        - all\n",
    "        - any\n",
    "        \n",
    "Process to generate hhold_train:\n",
    "    1. Take numeric and categorical data\n",
    "    2. For numeric, transform data using:\n",
    "        - MinMax scaler: mx_\n",
    "        - Standard scaler: sc_\n",
    "    3. For categorical, encode data:\n",
    "        - Use label encoding\n",
    "        - Use the label encoded data to perform one-hot-encoding\n",
    "        - Retain the label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indiv_vectorize_object_columns(train_data, test_data, agg_type=['mean', 'median', 'any', 'all']):\n",
    "    '''\n",
    "        agg_type: ['mean', 'median', 'any', 'all']\n",
    "    '''\n",
    "    \n",
    "    train_data = train_data.drop('country', axis=1)\n",
    "    test_data = test_data.drop('country', axis=1)\n",
    "\n",
    "    train_obj_data = train_data.select_dtypes(include=['object'])\n",
    "    test_obj_data = test_data[train_obj_data.columns]\n",
    "    \n",
    "    train_processed_data = pd.DataFrame()\n",
    "    test_processed_data = pd.DataFrame()\n",
    "    \n",
    "    for col in train_obj_data.columns:\n",
    "        # Take average of categorical values for each member of the household\n",
    "        train_group = pd.get_dummies(train_obj_data[col]).reset_index(0).groupby('id')\n",
    "        test_group = pd.get_dummies(test_obj_data[col]).reset_index(0).groupby('id')\n",
    "\n",
    "        for at in agg_type:\n",
    "\n",
    "            if at == 'mean':\n",
    "                train_vec_feat = train_group.mean()\n",
    "                test_vec_feat = test_group.mean()\n",
    "                \n",
    "            if at == 'median':\n",
    "                train_vec_feat = train_group.median()\n",
    "                test_vec_feat = test_group.median()\n",
    "                \n",
    "            if at == 'any':\n",
    "                train_vec_feat = 1 * train_group.any()\n",
    "                test_vec_feat = 1 * test_group.any()\n",
    "\n",
    "            if at == 'all':\n",
    "                train_vec_feat = 1 * train_group.all()\n",
    "                test_vec_feat = 1 * test_group.all()\n",
    "\n",
    "            common_cols = train_vec_feat.columns.intersection(test_vec_feat.columns)\n",
    "\n",
    "            train_vec_feat = train_vec_feat[common_cols]\n",
    "            test_vec_feat = test_vec_feat[common_cols]\n",
    "\n",
    "            train_vec_feat.columns = ['{}_{}'.format(at, cname) for cname in train_vec_feat.columns]\n",
    "            test_vec_feat.columns = ['{}_{}'.format(at, cname) for cname in test_vec_feat.columns]\n",
    "\n",
    "            if train_processed_data.empty:\n",
    "                train_processed_data = train_vec_feat\n",
    "            else:\n",
    "                train_processed_data = pd.concat([train_processed_data, train_vec_feat], axis=1)\n",
    "\n",
    "            if test_processed_data.empty:\n",
    "                test_processed_data = test_vec_feat\n",
    "            else:\n",
    "                test_processed_data = pd.concat([test_processed_data, test_vec_feat], axis=1)\n",
    "\n",
    "    train_processed_data['indiv_count'] = train_data.reset_index(0).groupby('id').count().max(axis=1)\n",
    "    test_processed_data['indiv_count'] = test_data.reset_index(0).groupby('id').count().max(axis=1)\n",
    "\n",
    "    return train_processed_data, test_processed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_categorical(train, test):\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "\n",
    "    cols = set(train.columns)\n",
    "    cat_cols = []\n",
    "    \n",
    "    # Target is of bool type so it will not be transformed.\n",
    "    \n",
    "    numeric = train.select_dtypes(include=['int64', 'float64'])\n",
    "    numeric_fill = numeric.mean()\n",
    "    \n",
    "    numeric = numeric.fillna(numeric_fill)\n",
    "    \n",
    "    train[numeric.columns] = numeric\n",
    "    test[numeric.columns] = test[numeric.columns].fillna(numeric_fill)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    mx = MinMaxScaler()\n",
    "\n",
    "    train = pd.concat(\n",
    "        [train, pd.DataFrame(\n",
    "            sc.fit_transform(numeric),\n",
    "            columns=['sc_{}'.format(i) for i in numeric.columns],\n",
    "            index=train.index\n",
    "        )], axis=1)\n",
    "    \n",
    "    test = pd.concat(\n",
    "        [test, pd.DataFrame(\n",
    "            sc.transform(test[numeric.columns].fillna(numeric_fill)),\n",
    "            columns=['sc_{}'.format(i) for i in numeric.columns],\n",
    "            index=test.index\n",
    "        )], axis=1)\n",
    "    \n",
    "    train = pd.concat(\n",
    "        [train, pd.DataFrame(\n",
    "            mx.fit_transform(numeric),\n",
    "            columns=['mx_{}'.format(i) for i in numeric.columns],\n",
    "            index=train.index\n",
    "        )], axis=1)\n",
    "    \n",
    "    test = pd.concat(\n",
    "        [test, pd.DataFrame(\n",
    "            mx.transform(test[numeric.columns].fillna(numeric_fill)),\n",
    "            columns=['mx_{}'.format(i) for i in numeric.columns],\n",
    "            index=test.index\n",
    "        )], axis=1)\n",
    "    \n",
    "    \n",
    "    num_cols = set(numeric.columns)\n",
    "    \n",
    "    for col in tqdm(cols):\n",
    "        if train[col].dtype == 'object':\n",
    "            train[col] = train[col].fillna('N/A')\n",
    "            test[col] = test[col].fillna('N/A')\n",
    "\n",
    "            train[col] = train[col].apply(str)\n",
    "            test[col] = test[col].apply(str)\n",
    "\n",
    "            le = LabelEncoder()\n",
    "            ohe = OneHotEncoder()\n",
    "\n",
    "            train_vals = list(train[col].unique())\n",
    "            test_vals = list(test[col].unique())\n",
    "            le.fit(train_vals + test_vals)\n",
    "            train[col] = le.transform(train[col])\n",
    "            test[col] = le.transform(test[col])\n",
    "            \n",
    "            cat_cols.append(col)\n",
    "\n",
    "    train_ohe = pd.get_dummies(train[cat_cols].astype(str))\n",
    "    test_ohe = pd.get_dummies(test[cat_cols].astype(str))\n",
    "\n",
    "    ohe_common = train_ohe.columns.intersection(test_ohe.columns)\n",
    "\n",
    "    train = pd.concat([train, train_ohe], axis=1)\n",
    "    test = pd.concat([test, test_ohe], axis=1)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing country A data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 345/345 [00:02<00:00, 125.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing country B data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:01<00:00, 284.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing country C data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 222.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for country_code in ['A', 'B', 'C']:\n",
    "    print('Processing country {} data...'.format(country_code))\n",
    "    hhold_train, indiv_train = load_data(country_code, data_part='train')\n",
    "    hhold_test, indiv_test = load_data(country_code, data_part='test')\n",
    "\n",
    "    indiv_cat_train, indiv_cat_test = indiv_vectorize_object_columns(indiv_train, indiv_test)\n",
    "\n",
    "    indiv_cat_train.to_hdf(os.path.join(DATA_DIR, 'indiv_cat_train.hdf'), '{}_indiv_cat_train'.format(country_code))    \n",
    "    indiv_cat_test.to_hdf(os.path.join(DATA_DIR, 'indiv_cat_test.hdf'), '{}_indiv_cat_test'.format(country_code))\n",
    "\n",
    "    hh_train, hh_test = transform_categorical(hhold_train, hhold_test)\n",
    "\n",
    "    hh_train.to_csv(os.path.join(DATA_DIR, '{}-hhold-transformed-train.csv'.format(country_code)))\n",
    "    hh_test.to_csv(os.path.join(DATA_DIR, '{}-hhold-transformed-test.csv'.format(country_code)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
